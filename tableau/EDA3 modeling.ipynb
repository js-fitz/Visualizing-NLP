{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "ss_scrape = pd.read_csv('data/ss_scrape.csv', low_memory=False)\n",
    "gpt2_scrape = pd.read_csv('data/gpt2_scrape.csv', low_memory=False)\n",
    "all_scrape = pd.concat([ss_scrape, gpt2_scrape], sort=False)          # combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_scrape.shape, gpt2_scrape.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List top words in each subreddit  by count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(max_features=10000, ngram_range=(1,4), token_pattern=r'\\b[^\\d\\W]+\\b')\n",
    "df_cv = tfid.fit_transform(all_scrape['title'])\n",
    "df_cv = pd.DataFrame(df_cv.todense(), columns=tfid.get_feature_names())\n",
    "\n",
    "ss_cv = df_cv.loc[:999]  # vectorized subsum\n",
    "gp_cv = df_cv.loc[1000:] # vectorized gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list words by frequency in sub\n",
    "n=1500\n",
    "ss_freq = list(ss_cv.sum().sort_values(ascending=False)[:n].index)\n",
    "gp_freq = list(gp_cv.sum().sort_values(ascending=False)[:n].index)\n",
    "top_all = set(ss_freq+gp_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Transform Combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs, define X, y\n",
    "X = all_scrape['title']\n",
    "y = all_scrape['sr']\n",
    "\n",
    "# tfidf transform\n",
    "tfid = TfidfVectorizer(max_features=10000, ngram_range=(1,4), token_pattern=r'\\b[^\\d\\W]+\\b')\n",
    "Xf = tfid.fit_transform(X)\n",
    "Xf = pd.DataFrame(Xf.toarray(), columns=tfid.get_feature_names())\n",
    "\n",
    "# keep only cols from df_freq\n",
    "Xf = Xf[[w for w in top_all if w in Xf.columns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xf, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cval: 0.7220000000000001\n",
      "train: 0.9053333333333333 test: 0.726\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1*np.e**-20)\n",
    "mnb.fit(Xf, y)\n",
    "print('cval:', cross_val_score(mnb, Xf, y, cv=5).mean())\n",
    "mnb.fit(X_train, y_train)\n",
    "print('train:', mnb.score(X_train, y_train), 'test:', mnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop strong mnb coefs\n",
    "mnb_coefs = pd.DataFrame({'word': Xf.columns, 'mnb coef': mnb.coef_[0]}).sort_values('mnb coef')[-100:]\n",
    "Xfr = Xf[[c for c in Xf.columns if c not in mnb_coefs['word'].values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cval: 0.7190000000000001\n",
      "train: 0.908 test: 0.722\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1*np.e**-20)\n",
    "mnb.fit(Xfr, y)\n",
    "print('cval:', cross_val_score(mnb, Xfr, y, cv=5).mean())\n",
    "Xr_train, Xr_test, y_train, y_test = train_test_split(Xfr, y, random_state=42)\n",
    "mnb.fit(Xr_train, y_train)\n",
    "print('train:', mnb.score(Xr_train, y_train), 'test:', mnb.score(Xr_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (Ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cval: 0.7185\n",
      "train: 0.96 test: 0.732\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(Cs=np.logspace(.1, 1.5, 50), penalty='l2', solver='lbfgs', max_iter=5000, cv=3)\n",
    "lr.fit(Xf, y)\n",
    "print('cval:', cross_val_score(lr, Xf, y, cv=5).mean())\n",
    "Xf_train, Xf_test, y_train, y_test = train_test_split(Xf, y, random_state=42)\n",
    "lr.fit(Xf_train, y_train)\n",
    "print('train:', lr.score(Xf_train, y_train), 'test:', lr.score(Xf_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.33441064])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop strong ridge coefs\n",
    "lr_coefs = pd.DataFrame({'word': Xf.columns, 'lr coef': lr.coef_[0]}).sort_values('lr coef')[-100:]\n",
    "Xfr = Xf[[c for c in Xf.columns if c not in lr_coefs['word'].values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cval: 0.6915\n",
      "train: 0.9493333333333334 test: 0.71\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegressionCV(Cs=np.logspace(.1, 1, 50), penalty='l2', solver='lbfgs', max_iter=5000, cv=3)\n",
    "lr.fit(Xfr, y)\n",
    "print('cval:', cross_val_score(lr, Xfr, y, cv=5).mean())\n",
    "Xfr_train, Xfr_test, y_train, y_test = train_test_split(Xfr, y, random_state=42)\n",
    "lr.fit(Xfr_train, y_train)\n",
    "print('train:', lr.score(Xfr_train, y_train), 'test:', lr.score(Xfr_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xf, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradboost = GradientBoostingClassifier(max_depth=5)\n",
    "gradboost.fit(X_train, y_train)\n",
    "gradboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xf, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegressionCV(Cs=np.logspace(.1, 1, 50), penalty='l2', solver='lbfgs', max_iter=5000, cv=3)\n",
    "lr.fit(Xf, y)\n",
    "print('cval:', cross_val_score(lr, Xf, y, cv=5).mean())\n",
    "Xf_train, Xf_test, y_train, y_test = train_test_split(Xf, y, random_state=42)\n",
    "lr.fit(Xf_train, y_train)\n",
    "print('train:', lr.score(Xf_train, y_train), 'test:', lr.score(Xf_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.532, 0.496)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=1*np.e**-20)\n",
    "mnb.fit(Xf, y)\n",
    "print('cval:', cross_val_score(mnb, Xf, y, cv=5).mean())\n",
    "mnb.fit(X_train, y_train)\n",
    "print('train:', mnb.score(X_train, y_train), 'test:', mnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grb = GradientBoostingClassifier(max_depth=4)\n",
    "grb.fit(X_train, y_train)\n",
    "grb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([ 1.25892541,  1.31331029,  1.37004456,  1.42922973,  1.49097166,\n",
       "        1.5553808 ,  1.62257239,  1.69266662,  1.76578887,  1.84206997,\n",
       "        1.92164637,  2.00466042,  2.09126064,  2.18160194,  2.27584593,\n",
       "        2.3741612 ,  2.47672365,  2.58371673,  2.69533186,  2.8117687 ,\n",
       "        2.93323554,  3.05994969,  3.19213781,  3.33003639,  3.47389211,\n",
       "        3.62396232,  3.78051548,  3.94383164,  4.11420298,  4.2...\n",
       "        5.5316812 ,  5.77064675,  6.01993548,  6.27999335,  6.55128557,\n",
       "        6.83429746,  7.12953531,  7.43752728,  7.75882432,  8.09400122,\n",
       "        8.44365757,  8.80841888,  9.18893768,  9.58589468, 10.        ]),\n",
       "                     class_weight=None, cv=3, dual=False, fit_intercept=True,\n",
       "                     intercept_scaling=1.0, l1_ratios=None, max_iter=5000,\n",
       "                     multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                     random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionCV(Cs=np.logspace(.1, 1, 50), penalty='l2', solver='lbfgs', max_iter=5000, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.18893768])"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VotingClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52d2478c761b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vote = VotingClassifier([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLogisticRegressionCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'mnb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'grb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'VotingClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "    ('lr', LogisticRegressionCV(Cs=np.logspace(.1, 1, 50), penalty='l2', solver='lbfgs', max_iter=5000, cv=3)),\n",
    "    ('mnb', MultinomialNB()),\n",
    "    ('grb', GradientBoostingClassifier()),\n",
    "])\n",
    "vote_params = {\n",
    "    'grb__max_depth': [4, 3],\n",
    "    'weights': [[.1,.8,.1],[.50,.25,.25],[.25,.50,.25],[.25,.25,.50],]\n",
    "}\n",
    "gs = GridSearchCV(vote, param_grid=vote_params, cv=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_) # cross val score\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
